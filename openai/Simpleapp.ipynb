{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Simple Gen AI APP Using Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")\n",
    "## Langsmith Tracking\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=os.getenv(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=os.getenv(\"LANGCHAIN_PROJECT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Data Ingestion--From the website we need to scrape the data\n",
    "from langchain_community.document_loaders import WebBaseLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.document_loaders.web_base.WebBaseLoader at 0x121b16300>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader=WebBaseLoader(\"https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier\")\n",
    "loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='\\n\\n\\n\\n\\nOptimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith\\n\\n\\n\\n\\n\\n\\nSkip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringTutorialsOptimize a classifierOn this pageOptimize a classifier\\nThis tutorial walks through optimizing a classifier based on user a feedback.\\nClassifiers are great to optimize because its generally pretty simple to collect the desired output, which makes it easy to create few shot examples based on user feedback.\\nThat is exactly what we will do in this example.\\nThe objective‚Äã\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting started‚Äã\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.\\nimport openaifrom langsmith import traceable, Clientimport uuidclient = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Issue: {text}\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                )            }        ],    ).choices[0].message.content\\nWe can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automations‚Äã\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.\\n\\nThe second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.\\n\\nUpdate the application‚Äã\\nWe can now update our code to pull down the dataset we are sending runs to.\\nOnce we pull it down, we can create a string with the examples in it.\\nWe can then put this string as part of the prompt!\\n### NEW CODE #### Initialize the LangSmith Client so we can use to get the datasetls_client = Client()# Create a function that will take in a list of examples and format them into a stringdef create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)### NEW CODE ###client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    # We can now pull down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))  # <- New Code    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.content\\nIf now run the application with a similar input as before, we can see that it correctly learns that anything related to docs (even if a bug) should be classified as documentation\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"address bug in documentation\",    langsmith_extra={\"run_id\": run_id})\\nSemantic search over examples‚Äã\\nOne additional thing we can do is only use the most semantically similar examples.\\nThis is useful when you start to build up a lot of examples.\\nIn order to do this, we can first define an example to find the k most similar examples:\\nimport numpy as npdef find_similar(examples, topic, k=5):    inputs = [e.inputs[\\'topic\\'] for e in examples] + [topic]    vectors = client.embeddings.create(input=inputs, model=\"text-embedding-3-small\")    vectors = [e.embedding for e in vectors.data]    vectors = np.array(vectors)    args = np.argsort(-vectors.dot(vectors[-1])[:-1])[:5]    examples = [examples[i] for i in args]    return examples\\nWe can then use that in the application\\nls_client = Client()def create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))    examples = find_similar(examples, topic)    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.contentWas this page helpful?You can leave detailed feedback on GitHub.PreviousPrompt engineering tutorialsNextPrompt engineering how-to guidesThe objectiveGetting startedSet up automationsUpdate the applicationSemantic search over examplesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.\\n\\n')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs=loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load Data--> Docs-->Divide our Docuemnts into chunks dcouments-->text-->vectors-->Vector Embeddings--->Vector Store DB\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter=RecursiveCharacterTextSplitter(chunk_size=1000,chunk_overlap=200)\n",
    "documents=text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Skip to main contentLearn the essentials of LangSmith in the new Introduction to LangSmith course!  Enroll for free. API ReferenceRESTPythonSearchRegionUSEUGo to AppQuick StartObservabilityEvaluationPrompt EngineeringTutorialsOptimize a classifierHow-to GuidesPlaygroundPromptsConceptual GuideDeployment (LangGraph Platform)AdministrationSelf-hostingPricingReferenceCloud architecture and scalabilityAuthz and AuthnAuthentication methodsdata_formatsEvaluationDataset transformationsRegions FAQsdk_referencePrompt EngineeringTutorialsOptimize a classifierOn this pageOptimize a classifier\\nThis tutorial walks through optimizing a classifier based on user a feedback.\\nClassifiers are great to optimize because its generally pretty simple to collect the desired output, which makes it easy to create few shot examples based on user feedback.\\nThat is exactly what we will do in this example.\\nThe objective‚Äã\\nIn this example, we will build a bot that classify GitHub issues based on their title.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='That is exactly what we will do in this example.\\nThe objective‚Äã\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting started‚Äã\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.\\nimport openaifrom langsmith import traceable, Clientimport uuidclient = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Issue: {text}\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                )            }        ],    ).choices[0].message.content\\nWe can then start to interact with it.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automations‚Äã\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='The second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='Update the application‚Äã\\nWe can now update our code to pull down the dataset we are sending runs to.\\nOnce we pull it down, we can create a string with the examples in it.\\nWe can then put this string as part of the prompt!'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='### NEW CODE #### Initialize the LangSmith Client so we can use to get the datasetls_client = Client()# Create a function that will take in a list of examples and format them into a stringdef create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)### NEW CODE ###client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    # We can now pull down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples ='),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='down the examples from the dataset    # We do this inside the function so it always get the most up-to-date examples,    # But this can be done outside and cached for speed if desired    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))  # <- New Code    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.content'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='If now run the application with a similar input as before, we can see that it correctly learns that anything related to docs (even if a bug) should be classified as documentation\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"address bug in documentation\",    langsmith_extra={\"run_id\": run_id})\\nSemantic search over examples‚Äã\\nOne additional thing we can do is only use the most semantically similar examples.\\nThis is useful when you start to build up a lot of examples.\\nIn order to do this, we can first define an example to find the k most similar examples:\\nimport numpy as npdef find_similar(examples, topic, k=5):    inputs = [e.inputs[\\'topic\\'] for e in examples] + [topic]    vectors = client.embeddings.create(input=inputs, model=\"text-embedding-3-small\")    vectors = [e.embedding for e in vectors.data]    vectors = np.array(vectors)    args = np.argsort(-vectors.dot(vectors[-1])[:-1])[:5]    examples = [examples[i] for i in args]    return examples'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then use that in the application'),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='ls_client = Client()def create_example_string(examples):    final_strings = []    for e in examples:        final_strings.append(f\"Input: {e.inputs[\\'topic\\']}\\\\n> {e.outputs[\\'output\\']}\")    return \"\\\\n\\\\n\".join(final_strings)client = openai.Client()available_topics = [    \"bug\",    \"improvement\",    \"new_feature\",    \"documentation\",    \"integration\",]prompt_template = \"\"\"Classify the type of the issue as one of {topics}.Here are some examples:{examples}Begin!Issue: {text}>\"\"\"@traceable(    run_type=\"chain\",    name=\"Classifier\",)def topic_classifier(    topic: str):    examples = list(ls_client.list_examples(dataset_name=\"classifier-github-issues\"))    examples = find_similar(examples, topic)    example_string = create_example_string(examples)    return client.chat.completions.create(        model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format('),\n",
       " Document(metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='model=\"gpt-4o-mini\",        temperature=0,        messages=[            {                \"role\": \"user\",                \"content\": prompt_template.format(                    topics=\\',\\'.join(available_topics),                    text=topic,                    examples=example_string,                )            }        ],    ).choices[0].message.contentWas this page helpful?You can leave detailed feedback on GitHub.PreviousPrompt engineering tutorialsNextPrompt engineering how-to guidesThe objectiveGetting startedSet up automationsUpdate the applicationSemantic search over examplesCommunityDiscordTwitterGitHubDocs CodeLangSmith SDKPythonJS/TSMoreHomepageBlogLangChain Python DocsLangChain JS/TS DocsCopyright ¬© 2025 LangChain, Inc.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "embeddings=OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import FAISS\n",
    "vectorstoredb=FAISS.from_documents(documents,embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x139db7c50>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'That is exactly what we will do in this example.\\nThe objective‚Äã\\nIn this example, we will build a bot that classify GitHub issues based on their title.\\nIt will take in a title and classify it into one of many different classes.\\nThen, we will start to collect user feedback and use that to shape how this classifier performs.\\nGetting started‚Äã\\nTo get started, we will first set it up so that we send all traces to a specific project.\\nWe can do this by setting an environment variable:\\nimport osos.environ[\"LANGCHAIN_PROJECT\"] = \"classifier\"\\nWe can then create our initial application. This will be a really simple function that just takes in a GitHub issue title and tries to label it.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Query From a vector db\n",
    "query=\"send trace to specific project\"\n",
    "result=vectorstoredb.similarity_search(query)\n",
    "result[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llm=ChatOpenAI(model=\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x13a364a10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13a3667e0>, root_client=<openai.OpenAI object at 0x13a33b140>, root_async_client=<openai.AsyncOpenAI object at 0x13a364a70>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Retrieval Chain, Document chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "Answer the following question based only on the provided context:\n",
    "<context>\n",
    "{context}\n",
    "</context>\n",
    "\n",
    "\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "document_chain=create_stuff_documents_chain(llm,prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The context provided instructs on setting up the process to send all traces to a specific project by setting an environment variable. However, it does not contain a specific question to answer. Could you please provide the question you would like answered based on this context?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "document_chain.invoke({\n",
    "    \"input\":\"send trace to specific project\",\n",
    "    \"context\":[Document(page_content=\"To get started, we will first set it up so that we send all traces to a specific project. We can do this by setting an environment variable:\")]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we want the documents to first come from the retriever we just set up. That way, we can use the retriever to dynamically select the most relevant documents and pass those in for a given question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.vectorstores.faiss.FAISS at 0x139db7c50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Input--->Retriever--->vectorstoredb\n",
    "\n",
    "vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vectorstoredb.as_retriever()\n",
    "from langchain.chains import create_retrieval_chain\n",
    "retrieval_chain=create_retrieval_chain(retriever,document_chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['FAISS', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x139db7c50>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template='\\nAnswer the following question based only on the provided context:\\n<context>\\n{context}\\n</context>\\n\\n\\n'), additional_kwargs={})])\n",
       "            | ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x13a364a10>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x13a3667e0>, root_client=<openai.OpenAI object at 0x13a33b140>, root_async_client=<openai.AsyncOpenAI object at 0x13a364a70>, model_name='gpt-4o', model_kwargs={}, openai_api_key=SecretStr('**********'))\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How can positive feedback be used in future iterations according to the context?'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get the response form the LLM\n",
    "response=retrieval_chain.invoke({\"input\":\"collect feedback in two forms\"})\n",
    "response['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'collect feedback in two forms',\n",
       " 'context': [Document(id='1d6e045c-8181-4d24-b33b-c9aed35ec464', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.'),\n",
       "  Document(id='38c81a88-a1bd-4e13-abc7-12391fd10217', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automations‚Äã\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'),\n",
       "  Document(id='d8796792-b38d-4323-b6d7-a5ff4f3900b1', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then use that in the application'),\n",
       "  Document(id='31080e6d-6234-4327-8a25-3f4481387a07', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='The second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.')],\n",
       " 'answer': 'How can positive feedback be used in future iterations according to the context?'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='1d6e045c-8181-4d24-b33b-c9aed35ec464', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then start to interact with it.\\nWhen interacting with it, we will generate the LangSmith run id ahead of time and pass that into this function.\\nWe do this so we can attach feedback later on.\\nHere\\'s how we can invoke the application:\\nrun_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})\\nHere\\'s how we can attach feedback after.\\nWe can collect feedback in two forms.\\nFirst, we can collect \"positive\" feedback - this is for examples that the model got right.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in LCEL\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"user-score\",    score=1.0,)\\nNext, we can focus on collecting feedback that corresponds to a \"correction\" to the generation.\\nIn this example the model will classify it as a bug, whereas I really want this to be classified as documentation.'),\n",
       " Document(id='38c81a88-a1bd-4e13-abc7-12391fd10217', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='In this example the model will classify it as a bug, whereas I really want this to be classified as documentation.\\nls_client = Client()run_id = uuid.uuid4()topic_classifier(    \"fix bug in documentation\",    langsmith_extra={\"run_id\": run_id})ls_client.create_feedback(    run_id,    key=\"correction\",    correction=\"documentation\")\\nSet up automations‚Äã\\nWe can now set up automations to move examples with feedback of some form into a dataset.\\nWe will set up two automations, one for positive feedback and the other for negative feedback.\\nThe first will take all runs with positive feedback and automatically add them to a dataset.\\nThe logic behind this is that any run with positive feedback we can use as a good example in future iterations.\\nLet\\'s create a dataset called classifier-github-issues to add this data to.'),\n",
       " Document(id='d8796792-b38d-4323-b6d7-a5ff4f3900b1', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='We can then use that in the application'),\n",
       " Document(id='31080e6d-6234-4327-8a25-3f4481387a07', metadata={'source': 'https://docs.smith.langchain.com/prompt_engineering/tutorials/optimize_classifier', 'title': 'Optimize a classifier | \\uf8ffü¶úÔ∏è\\uf8ffüõ†Ô∏è LangSmith', 'description': 'This tutorial walks through optimizing a classifier based on user a feedback.', 'language': 'en'}, page_content='The second will take all runs with a correction and use a webhook to add them to a dataset.\\nWhen creating this webhook, we will select the option to \"Use Corrections\".\\nThis option will make it so that when creating a dataset from a run, rather than using the output of the run\\nas the gold-truth output of the datapoint, it will use the correction.')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['context']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
